{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     self-signed certificate in certificate chain\n",
      "[nltk_data]     (_ssl.c:1000)>\n",
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     self-signed certificate in certificate chain\n",
      "[nltk_data]     (_ssl.c:1000)>\n",
      "[nltk_data] Error loading wordnet: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     self-signed certificate in certificate chain\n",
      "[nltk_data]     (_ssl.c:1000)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import zipfile\n",
    "import os\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from numpy.linalg import pinv\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/student/vishaka/collection_data.csv'\n",
    "chunk_size = 10000\n",
    "processed_chunks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "    chunk = chunk[['document_id', 'document_text']]\n",
    "    processed_chunks.append(chunk)\n",
    "collection_df = pd.concat(processed_chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Manhattan Project and its atomic bomb help...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Essay on The Manhattan Project - The Manhattan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>The Manhattan Project was the name for a proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>versions of each volume as well as complementa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Manhattan Project. This once classified ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8841817</th>\n",
       "      <td>8841818</td>\n",
       "      <td>When metal salts emit short wavelengths of vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8841818</th>\n",
       "      <td>8841819</td>\n",
       "      <td>Thousands of people across the United States w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8841819</th>\n",
       "      <td>8841820</td>\n",
       "      <td>The recipe that creates blue, for example, inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8841820</th>\n",
       "      <td>8841821</td>\n",
       "      <td>On Independence Days of yore, old-timey crowds...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8841821</th>\n",
       "      <td>8841822</td>\n",
       "      <td>View full size image. Behind the scenes of the...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8841822 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         document_id                                      document_text\n",
       "0                  1  The Manhattan Project and its atomic bomb help...\n",
       "1                  2  Essay on The Manhattan Project - The Manhattan...\n",
       "2                  3  The Manhattan Project was the name for a proje...\n",
       "3                  4  versions of each volume as well as complementa...\n",
       "4                  5  The Manhattan Project. This once classified ph...\n",
       "...              ...                                                ...\n",
       "8841817      8841818  When metal salts emit short wavelengths of vis...\n",
       "8841818      8841819  Thousands of people across the United States w...\n",
       "8841819      8841820  The recipe that creates blue, for example, inc...\n",
       "8841820      8841821  On Independence Days of yore, old-timey crowds...\n",
       "8841821      8841822  View full size image. Behind the scenes of the...\n",
       "\n",
       "[8841822 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8841822, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the main reasons Hanford was selected as a site for the Manhattan Project's B Reactor was its proximity to the Columbia River, the largest river flowing into the Pacific Ocean from the North American coast.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection_df['document_text'][8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize preprocessing tools\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "\n",
    "# Load SpaCy's English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Define preprocessing functions\n",
    "def clean_text(text):\n",
    "    \"\"\"Clean text by removing special characters, numbers, and extra spaces.\"\"\"\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\d+', '', text)  # Remove digits\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    return text\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"Remove stopwords from the text.\"\"\"\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def lemmatize_text_spacy(text):\n",
    "    \"\"\"Lemmatize text using SpaCy.\"\"\"\n",
    "    doc = nlp(text)  # Process text with SpaCy\n",
    "    lemmatized_words = [token.lemma_ for token in doc if not token.is_punct]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "def preprocess_text_spacy(text):\n",
    "    \"\"\"Apply all preprocessing steps to the text using SpaCy for lemmatization.\"\"\"\n",
    "    text = clean_text(text)\n",
    "    text = remove_stopwords(text)\n",
    "    text = lemmatize_text_spacy(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_data_df=collection_df[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2587779/3035804518.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  collection_data_df['processed_document'] = collection_data_df['document_text'].apply(preprocess_text_spacy)\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the 'document' column of the DataFrame\n",
    "collection_data_df['processed_document'] = collection_data_df['document_text'].apply(preprocess_text_spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       document_text  \\\n",
      "0  The Manhattan Project and its atomic bomb help...   \n",
      "1  Essay on The Manhattan Project - The Manhattan...   \n",
      "2  The Manhattan Project was the name for a proje...   \n",
      "3  versions of each volume as well as complementa...   \n",
      "4  The Manhattan Project. This once classified ph...   \n",
      "\n",
      "                                  processed_document  \n",
      "0  manhattan project atomic bomb helped bring end...  \n",
      "1  essay manhattan project manhattan project manh...  \n",
      "2  manhattan project name project conduct world w...  \n",
      "3  version volume well complementary website firs...  \n",
      "4  manhattan project classify photograph feature ...  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows after preprocessing\n",
    "print(collection_data_df[['document_text', 'processed_document']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the TSV file\n",
    "qrels_train_df = pd.read_csv('/home/student/vishaka/data/qrels.train.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1185869</th>\n",
       "      <th>0</th>\n",
       "      <th>0.1</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1185868</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>597651</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>403613</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1183785</td>\n",
       "      <td>0</td>\n",
       "      <td>389</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>312651</td>\n",
       "      <td>0</td>\n",
       "      <td>616</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532755</th>\n",
       "      <td>19285</td>\n",
       "      <td>0</td>\n",
       "      <td>8841362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532756</th>\n",
       "      <td>558837</td>\n",
       "      <td>0</td>\n",
       "      <td>4989159</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532757</th>\n",
       "      <td>559149</td>\n",
       "      <td>0</td>\n",
       "      <td>8841547</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532758</th>\n",
       "      <td>706678</td>\n",
       "      <td>0</td>\n",
       "      <td>8841643</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532759</th>\n",
       "      <td>405466</td>\n",
       "      <td>0</td>\n",
       "      <td>8841735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532760 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1185869  0      0.1  1\n",
       "0       1185868  0       16  1\n",
       "1        597651  0       49  1\n",
       "2        403613  0       60  1\n",
       "3       1183785  0      389  1\n",
       "4        312651  0      616  1\n",
       "...         ... ..      ... ..\n",
       "532755    19285  0  8841362  1\n",
       "532756   558837  0  4989159  1\n",
       "532757   559149  0  8841547  1\n",
       "532758   706678  0  8841643  1\n",
       "532759   405466  0  8841735  1\n",
       "\n",
       "[532760 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_train_df.rename(columns={\n",
    "    qrels_train_df.columns[0]: 'query_id',\n",
    "    qrels_train_df.columns[1]: 'iteration',\n",
    "    qrels_train_df.columns[2]: 'document_id',\n",
    "    qrels_train_df.columns[3]: 'relevance_label'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    document_id                                      document_text  \\\n",
      "0             1  The Manhattan Project and its atomic bomb help...   \n",
      "1             2  Essay on The Manhattan Project - The Manhattan...   \n",
      "2             3  The Manhattan Project was the name for a proje...   \n",
      "3             4  versions of each volume as well as complementa...   \n",
      "4             5  The Manhattan Project. This once classified ph...   \n",
      "5             6  Nor will it attempt to substitute for the extr...   \n",
      "6             7  Manhattan Project. The Manhattan Project was a...   \n",
      "7             8  In June 1942, the United States Army Corps of ...   \n",
      "8             9  One of the main reasons Hanford was selected a...   \n",
      "9            10  group discussions, community boards or panels ...   \n",
      "10           11  punishment designed to repair the damage done ...   \n",
      "11           12  Tutorial: Introduction to Restorative Justice....   \n",
      "12           13  Organize volunteer community panels, boards, o...   \n",
      "13           14  The purpose of this paper is to point out a nu...   \n",
      "14           15  Each of these types of communitiesâthe geogr...   \n",
      "15           16  The approach is based on a theory of justice t...   \n",
      "16           17  Inherent in many peopleâs understanding of t...   \n",
      "17           18  Criminal justice, however, is not usually conc...   \n",
      "18           19  The circle includes a wide range of participan...   \n",
      "19           20  Phloem is a conductive (or vascular) tissue fo...   \n",
      "\n",
      "                                   processed_document  \n",
      "0   manhattan project atomic bomb helped bring end...  \n",
      "1   essay manhattan project manhattan project manh...  \n",
      "2   manhattan project name project conduct world w...  \n",
      "3   version volume well complementary website firs...  \n",
      "4   manhattan project classify photograph feature ...  \n",
      "5   attempt substitute extraordinarily rich litera...  \n",
      "6   manhattan project manhattan project research d...  \n",
      "7   june united states army corps engineersbegan m...  \n",
      "8   one main reason hanford select site manhattan ...  \n",
      "9   group discussion community board panel third p...  \n",
      "10  punishment design repair damage do victim comm...  \n",
      "11  tutorial introduction restorative justice rest...  \n",
      "12  organize volunteer community panel board commi...  \n",
      "13  purpose paper point number unresolved issue cr...  \n",
      "14  type communitiesâthe geographic community vict...  \n",
      "15  approach base theory justice consider crime wr...  \n",
      "16  inherent many peopleâs understanding notion ad...  \n",
      "17  criminal justice however usually conceptualise...  \n",
      "18  circle include wide range participant include ...  \n",
      "19  phloem conductive vascular tissue find plant p...  \n"
     ]
    }
   ],
   "source": [
    "print(collection_data_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   query_id  iteration  document_id  relevance_label\n",
      "0   1185868          0           16                1\n",
      "1    597651          0           49                1\n",
      "2    403613          0           60                1\n",
      "3   1183785          0          389                1\n",
      "4    312651          0          616                1\n",
      "Unique Query IDs: [1185868  597651  403613 1183785  312651   80385  645590  543163  608727\n",
      "  695572  441765  738038  932391  932612  850072  313342  852302  100098\n",
      "  862916  608175  696762  900736   17472   84453 1168119  852919  416310\n",
      "  637313   10957  582917  608730]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Extract the document IDs from the first 20,000 rows of collection_data\n",
    "doc_ids_within_1000 = collection_data_df[:1000]['document_id'].tolist()\n",
    "\n",
    "# Step 2: Filter queries_train_df based on document IDs\n",
    "filtered_queries = qrels_train_df[qrels_train_df['document_id'].isin(doc_ids_within_1000)]\n",
    "\n",
    "# Display the result\n",
    "print(filtered_queries.head())\n",
    "\n",
    "# If you want to fetch only the query_id column, you can do this:\n",
    "query_ids_within_1000 = filtered_queries['query_id'].unique()\n",
    "print(\"Unique Query IDs:\", query_ids_within_1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_train_df = pd.read_csv('/home/student/vishaka/data/queries.train.tsv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     121352                                     define extreme\n",
      "0    634306           what does chattel mean on credit history\n",
      "1    920825            what was the great leap forward brainly\n",
      "2    510633                tattoo fixers how much does it cost\n",
      "3    737889                  what is decentralization process.\n",
      "4    278900  how many cars enter the la jolla concours d' e...\n",
      "5    674172                      what is a bank transit number\n",
      "6    303205     how much can i contribute to nondeductible ira\n",
      "7    570009         what are the four major groups of elements\n",
      "8    492875                              sanitizer temperature\n",
      "9     54528               blood clots in urine after menopause\n",
      "10   203218                                   highmark address\n",
      "11   473204     per sf cost in california for tenant build out\n",
      "12   738368                             what is delta in2ition\n",
      "13   507001              symptoms of an enlarged heart in dogs\n",
      "14   466926       number of times congress voted to repeal aca\n",
      "15   837327    what is the official color of army rank stripes\n",
      "16   406897      is colostrum beneficial for 3 week old calves\n",
      "17  1181095                how is a behavioral crisis defined?\n",
      "18   224811                        how does a firefly light up\n",
      "19   730323                       what is choice warranty plus\n"
     ]
    }
   ],
   "source": [
    "print(queries_train_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_train_df.rename(columns={\n",
    "    queries_train_df.columns[0]: 'query_id',\n",
    "    queries_train_df.columns[1]: 'query'\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        query_id                                              query\n",
      "0         634306           what does chattel mean on credit history\n",
      "1         920825            what was the great leap forward brainly\n",
      "2         510633                tattoo fixers how much does it cost\n",
      "3         737889                  what is decentralization process.\n",
      "4         278900  how many cars enter the la jolla concours d' e...\n",
      "...          ...                                                ...\n",
      "808725    633855             what does canada post regulations mean\n",
      "808726   1059728                            wholesale lularoe price\n",
      "808727    210839                      how can i watch the day after\n",
      "808728    908165              what to use instead of pgp in windows\n",
      "808729     50393     benefits of boiling lemons and drinking juice.\n",
      "\n",
      "[808730 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(queries_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        query_id                                              query\n",
      "4872      312651  how much does an average person make for tutoring\n",
      "66840     852302                         what is the unit for pulse\n",
      "71566     900736                        what teas are good for what\n",
      "106491    608727                     what county is lodi california\n",
      "117489    738038                            what is defamation harm\n",
      "123294    645590                     what does physical medicine do\n",
      "209032    852919                   what is the vehicle height on rv\n",
      "235206    637313                     what does extreme obesity mean\n",
      "236971    850072                      what is the temp in amsterdam\n",
      "299645     80385       can you use a calculator on the compass test\n",
      "355147    696762                               what is a pulse rate\n",
      "369622    695572                                what is a post code\n",
      "410751    608175                           what county is lake city\n",
      "453329   1168119                            weather in amsterdam in\n",
      "489467    313342                 how much does car seat covers cost\n",
      "498476     84453                           cause of pain above ribs\n",
      "521533    403613  is autoimmune hepatitis a bile acid synthesis ...\n",
      "530773   1185868  _________ justice is designed to repair the ha...\n",
      "531190    608730                        what county is lodi, ca in?\n",
      "563130    416310                           is libel against the law\n",
      "570026    582917                    what can you use a compass for?\n",
      "607269    543163                       weather history in amsterdam\n",
      "612819    932612                              what's the normal bpm\n",
      "629734   1183785                                     elegxo meaning\n",
      "671415    441765                             lodi is in what county\n",
      "677178    932391                         what's the meaning of wifi\n",
      "692857    100098                   cortana what's the longest word.\n",
      "695457    597651                          what color is amber urine\n",
      "761834     10957                      actress who play wonder woman\n",
      "775975    862916                       what is wifi radio frequency\n",
      "798094     17472            amsterdam average temperatures by month\n"
     ]
    }
   ],
   "source": [
    "filtered_queries_df = queries_train_df[queries_train_df['query_id'].isin(query_ids_within_1000)]\n",
    "\n",
    "# Display the result\n",
    "print(filtered_queries_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_data_df.to_csv('collection_data_df_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels_train_df.to_csv('qrels_train_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_queries_df.to_csv('filtered_queries_df_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_queries_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_extra_rows = 19\n",
    "extra_noise_df = filtered_queries_df.sample(n=num_extra_rows, replace=True, random_state=42)\n",
    "noisy_queries_df_1000 = pd.concat([filtered_queries_df, extra_noise_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query_id</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>312651</td>\n",
       "      <td>how much does an average person make for tutoring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>852302</td>\n",
       "      <td>what is the unit for pulse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>900736</td>\n",
       "      <td>what teas are good for what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>608727</td>\n",
       "      <td>what county is lodi california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>738038</td>\n",
       "      <td>what is defamation harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>645590</td>\n",
       "      <td>what does physical medicine do</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>852919</td>\n",
       "      <td>what is the vehicle height on rv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>637313</td>\n",
       "      <td>what does extreme obesity mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>850072</td>\n",
       "      <td>what is the temp in amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80385</td>\n",
       "      <td>can you use a calculator on the compass test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>696762</td>\n",
       "      <td>what is a pulse rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>695572</td>\n",
       "      <td>what is a post code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>608175</td>\n",
       "      <td>what county is lake city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1168119</td>\n",
       "      <td>weather in amsterdam in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>313342</td>\n",
       "      <td>how much does car seat covers cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>84453</td>\n",
       "      <td>cause of pain above ribs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>403613</td>\n",
       "      <td>is autoimmune hepatitis a bile acid synthesis ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1185868</td>\n",
       "      <td>_________ justice is designed to repair the ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>608730</td>\n",
       "      <td>what county is lodi, ca in?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>416310</td>\n",
       "      <td>is libel against the law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>582917</td>\n",
       "      <td>what can you use a compass for?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>543163</td>\n",
       "      <td>weather history in amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>932612</td>\n",
       "      <td>what's the normal bpm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1183785</td>\n",
       "      <td>elegxo meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>441765</td>\n",
       "      <td>lodi is in what county</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>932391</td>\n",
       "      <td>what's the meaning of wifi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100098</td>\n",
       "      <td>cortana what's the longest word.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>597651</td>\n",
       "      <td>what color is amber urine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10957</td>\n",
       "      <td>actress who play wonder woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>862916</td>\n",
       "      <td>what is wifi radio frequency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>17472</td>\n",
       "      <td>amsterdam average temperatures by month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>852919</td>\n",
       "      <td>what is the vehicle height on rv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>416310</td>\n",
       "      <td>is libel against the law</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10957</td>\n",
       "      <td>actress who play wonder woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>313342</td>\n",
       "      <td>how much does car seat covers cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>696762</td>\n",
       "      <td>what is a pulse rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>637313</td>\n",
       "      <td>what does extreme obesity mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>10957</td>\n",
       "      <td>actress who play wonder woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>582917</td>\n",
       "      <td>what can you use a compass for?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>852919</td>\n",
       "      <td>what is the vehicle height on rv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>932391</td>\n",
       "      <td>what's the meaning of wifi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>608730</td>\n",
       "      <td>what county is lodi, ca in?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>932612</td>\n",
       "      <td>what's the normal bpm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>696762</td>\n",
       "      <td>what is a pulse rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>696762</td>\n",
       "      <td>what is a pulse rate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1183785</td>\n",
       "      <td>elegxo meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>582917</td>\n",
       "      <td>what can you use a compass for?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>608727</td>\n",
       "      <td>what county is lodi california</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>637313</td>\n",
       "      <td>what does extreme obesity mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1183785</td>\n",
       "      <td>elegxo meaning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    query_id                                              query\n",
       "0     312651  how much does an average person make for tutoring\n",
       "1     852302                         what is the unit for pulse\n",
       "2     900736                        what teas are good for what\n",
       "3     608727                     what county is lodi california\n",
       "4     738038                            what is defamation harm\n",
       "5     645590                     what does physical medicine do\n",
       "6     852919                   what is the vehicle height on rv\n",
       "7     637313                     what does extreme obesity mean\n",
       "8     850072                      what is the temp in amsterdam\n",
       "9      80385       can you use a calculator on the compass test\n",
       "10    696762                               what is a pulse rate\n",
       "11    695572                                what is a post code\n",
       "12    608175                           what county is lake city\n",
       "13   1168119                            weather in amsterdam in\n",
       "14    313342                 how much does car seat covers cost\n",
       "15     84453                           cause of pain above ribs\n",
       "16    403613  is autoimmune hepatitis a bile acid synthesis ...\n",
       "17   1185868  _________ justice is designed to repair the ha...\n",
       "18    608730                        what county is lodi, ca in?\n",
       "19    416310                           is libel against the law\n",
       "20    582917                    what can you use a compass for?\n",
       "21    543163                       weather history in amsterdam\n",
       "22    932612                              what's the normal bpm\n",
       "23   1183785                                     elegxo meaning\n",
       "24    441765                             lodi is in what county\n",
       "25    932391                         what's the meaning of wifi\n",
       "26    100098                   cortana what's the longest word.\n",
       "27    597651                          what color is amber urine\n",
       "28     10957                      actress who play wonder woman\n",
       "29    862916                       what is wifi radio frequency\n",
       "30     17472            amsterdam average temperatures by month\n",
       "31    852919                   what is the vehicle height on rv\n",
       "32    416310                           is libel against the law\n",
       "33     10957                      actress who play wonder woman\n",
       "34    313342                 how much does car seat covers cost\n",
       "35    696762                               what is a pulse rate\n",
       "36    637313                     what does extreme obesity mean\n",
       "37     10957                      actress who play wonder woman\n",
       "38    582917                    what can you use a compass for?\n",
       "39    852919                   what is the vehicle height on rv\n",
       "40    932391                         what's the meaning of wifi\n",
       "41    608730                        what county is lodi, ca in?\n",
       "42    932612                              what's the normal bpm\n",
       "43    696762                               what is a pulse rate\n",
       "44    696762                               what is a pulse rate\n",
       "45   1183785                                     elegxo meaning\n",
       "46    582917                    what can you use a compass for?\n",
       "47    608727                     what county is lodi california\n",
       "48    637313                     what does extreme obesity mean\n",
       "49   1183785                                     elegxo meaning"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_queries_df_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_queries_df_1000.to_csv('noisy_queries_df_1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cur_decomposition(X, rank):\n",
    "    col_norms = np.sum(X**2, axis=0)\n",
    "    row_norms = np.sum(X**2, axis=1)\n",
    "    prob_cols = col_norms / np.sum(col_norms)\n",
    "    prob_rows = row_norms / np.sum(row_norms)\n",
    "    \n",
    "    selected_cols = np.random.choice(X.shape[1], rank, replace=False, p=prob_cols)\n",
    "    selected_rows = np.random.choice(X.shape[0], rank, replace=False, p=prob_rows)\n",
    "    \n",
    "    C = X[:, selected_cols]\n",
    "    R = X[selected_rows, :]\n",
    "    W = X[np.ix_(selected_rows, selected_cols)]\n",
    "    U = np.linalg.pinv(W)\n",
    "    return C, U, R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lda_gibbs_sampling(docs, num_topics, num_iter=1000, alpha=0.1, beta=0.1):\n",
    "    vocab = list(set(word for doc in docs for word in doc.split()))\n",
    "    term_doc_matrix = np.zeros((len(docs), len(vocab)))\n",
    "    \n",
    "    for i, doc in enumerate(docs):\n",
    "        for word in doc.split():\n",
    "            term_doc_matrix[i, vocab.index(word)] += 1\n",
    "    \n",
    "    num_docs, vocab_size = term_doc_matrix.shape\n",
    "    topic_assignments = np.random.randint(0, num_topics, size=(num_docs, vocab_size))\n",
    "    \n",
    "    doc_topic_counts = np.zeros((num_docs, num_topics))\n",
    "    topic_word_counts = np.zeros((num_topics, vocab_size))\n",
    "    topic_counts = np.zeros(num_topics)\n",
    "    \n",
    "    for d in range(num_docs):\n",
    "        for w in range(vocab_size):\n",
    "            topic = topic_assignments[d, w]\n",
    "            doc_topic_counts[d, topic] += term_doc_matrix[d, w]\n",
    "            topic_word_counts[topic, w] += term_doc_matrix[d, w]\n",
    "            topic_counts[topic] += term_doc_matrix[d, w]\n",
    "    \n",
    "    for _ in range(num_iter):\n",
    "        for d in range(num_docs):\n",
    "            for w in range(vocab_size):\n",
    "                word_count = term_doc_matrix[d, w]\n",
    "                if word_count == 0:\n",
    "                    continue\n",
    "                \n",
    "                topic = topic_assignments[d, w]\n",
    "                doc_topic_counts[d, topic] -= word_count\n",
    "                topic_word_counts[topic, w] -= word_count\n",
    "                topic_counts[topic] -= word_count\n",
    "                \n",
    "                topic_probs = ((doc_topic_counts[d, :] + alpha) * (topic_word_counts[:, w] + beta) / (topic_counts + beta * vocab_size))\n",
    "                topic_probs /= topic_probs.sum()\n",
    "                \n",
    "                new_topic = np.random.choice(num_topics, p=topic_probs)\n",
    "                topic_assignments[d, w] = new_topic\n",
    "                doc_topic_counts[d, new_topic] += word_count\n",
    "                topic_word_counts[new_topic, w] += word_count\n",
    "                topic_counts[new_topic] += word_count\n",
    "    \n",
    "    doc_topic_dist = (doc_topic_counts + alpha) / (doc_topic_counts.sum(axis=1, keepdims=True) + num_topics * alpha)\n",
    "    topic_word_dist = (topic_word_counts + beta) / (topic_word_counts.sum(axis=1, keepdims=True) + vocab_size * beta)\n",
    "    return doc_topic_dist, topic_word_dist, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_query_expansion(query, documents, model, top_n=3, original_weight=0.7, expanded_weight=0.3):\n",
    "    unique_terms = set(' '.join(documents).split())\n",
    "    term_embeddings = {term: model.encode(term) for term in unique_terms}\n",
    "    \n",
    "    query_terms = query.split()\n",
    "    query_embeddings = [model.encode(term) for term in query_terms]\n",
    "    query_embedding = np.mean(query_embeddings, axis=0)\n",
    "    \n",
    "    similarities = {term: cosine_similarity([query_embedding], [embedding])[0][0] for term, embedding in term_embeddings.items()}\n",
    "    expanded_terms = sorted(similarities, key=similarities.get, reverse=True)[:top_n]\n",
    "    \n",
    "    expanded_embeddings = [term_embeddings[term] for term in expanded_terms]\n",
    "    combined_embedding = original_weight * np.mean(query_embeddings, axis=0) + expanded_weight * np.mean(expanded_embeddings, axis=0)\n",
    "    \n",
    "    expanded_query_terms = set(query_terms).union(expanded_terms)\n",
    "    return combined_embedding, ' '.join(expanded_query_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents_with_cur(query, documents, model, lda_topics, lda_vocab, rank=10, top_n=5):\n",
    "    query_embedding, expanded_query = dynamic_query_expansion(query, documents, model)\n",
    "    print(f\"Expanded Query: '{expanded_query}'\\n\")\n",
    "    \n",
    "    document_embeddings = model.encode(documents)\n",
    "    C, U, R = cur_decomposition(document_embeddings, rank=rank)\n",
    "    reduced_document_embeddings = C @ U\n",
    "    reduced_query_embedding = query_embedding @ R.T\n",
    "    \n",
    "    similarities = cosine_similarity([reduced_query_embedding], reduced_document_embeddings).flatten()\n",
    "    top_indices = np.argsort(-similarities)[:top_n]\n",
    "    \n",
    "    print(\"LDA Topics Distribution for Top Documents:\")\n",
    "    for idx in top_indices:\n",
    "        doc_topics = lda_topics[idx]\n",
    "        print(f\"Document: {documents[idx]}\\nTopic Distribution: {doc_topics}\\n\")\n",
    "    \n",
    "    return top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-vishaka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
